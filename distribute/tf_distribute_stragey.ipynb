{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597647174029",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패션 MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels),(test_images,test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[...,None]\n",
    "test_images = test_images[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 [0,1]범위로 변경하기\n",
    "train_images = train_images/np.float32(255)\n",
    "test_images = test_images/np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
    }
   ],
   "source": [
    "# 변수와 그래프를 분산하는 전략 만들기\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프와 변수를 플랫폼과 무관한 SavedModel형식으로 내보냅니다. \n",
    "BUFFER_SIZE = len(train_images)\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분산 데이터셋들을 strategy.scope내에 생성\n",
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "    test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트들을 저장하기 위해서 체크포인트 디렉토리를 생성합니다.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.distribute.Strategy를 사용할 때, 손실은 어떻게 계산되어야 하나요\n",
    "# 4개의 GPU가 있고 입력 배치 크기가 64라고 하면 입력 배치 하나가 여러 개의 장치(4개의 GPU)에 분배\n",
    "# 16이 아니고 64로 나누는 이유는 그래디언터들이 각 장치에서 계산된 다음, 모든 장치를 동기화하기 위해 이 그래디언트 값들을 전부 더하기 때문\n",
    "with strategy.scope():\n",
    "    # reduction을 'none'으로 설정. 축소를 나중에 하고,\n",
    "    # GLOBAL_BATCH_SIZE(64)로 나눌 수 있습니다.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # 또는 loss_fn = tf.keras.losses.sparse_categorical_crossentropy를 사용해도 됩니다.\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='train_accuracy')\n",
    "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 옵티마이저는 `strategy.scope`에서 만들어져야 합니다.\n",
    "with strategy.scope():\n",
    "  model = create_model()\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      predictions = model(images, training=True)\n",
    "      loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss \n",
    "\n",
    "  def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "에포크 1, 손실: 0.1509631723165512, 정확도: 94.36333465576172, 테스트 손실: 0.27013859152793884, 테스트 정확도: 90.94000244140625\n에포크 2, 손실: 0.1411147266626358, 정확도: 94.76333618164062, 테스트 손실: 0.2779633104801178, 테스트 정확도: 90.8499984741211\n에포크 3, 손실: 0.13062159717082977, 정확도: 95.08666229248047, 테스트 손실: 0.28512436151504517, 테스트 정확도: 90.55000305175781\n에포크 4, 손실: 0.11979230493307114, 정확도: 95.5133285522461, 테스트 손실: 0.28708377480506897, 테스트 정확도: 91.11000061035156\n에포크 5, 손실: 0.11318346112966537, 정확도: 95.77999877929688, 테스트 손실: 0.2867371439933777, 테스트 정확도: 91.0199966430664\n에포크 6, 손실: 0.10535977780818939, 정확도: 96.10000610351562, 테스트 손실: 0.3474065661430359, 테스트 정확도: 89.95000457763672\n에포크 7, 손실: 0.09534232318401337, 정확도: 96.38833618164062, 테스트 손실: 0.3346357047557831, 테스트 정확도: 90.5999984741211\n에포크 8, 손실: 0.08927672356367111, 정확도: 96.65333557128906, 테스트 손실: 0.3230447471141815, 테스트 정확도: 91.00999450683594\n에포크 9, 손실: 0.08220059424638748, 정확도: 96.94332885742188, 테스트 손실: 0.35810238122940063, 테스트 정확도: 90.8699951171875\n에포크 10, 손실: 0.07740311324596405, 정확도: 97.11000061035156, 테스트 손실: 0.3570924401283264, 테스트 정확도: 90.8699951171875\n"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  # `experimental_run_v2`는 주어진 계산을 복사하고,\n",
    "  # 분산된 입력으로 계산을 수행합니다.\n",
    "  \n",
    "  @tf.function\n",
    "  def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.experimental_run_v2(train_step,\n",
    "                                                      args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                           axis=None)\n",
    " \n",
    "  @tf.function\n",
    "  def distributed_test_step(dataset_inputs):\n",
    "    return strategy.experimental_run_v2(test_step, args=(dataset_inputs,))\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    # 훈련 루프\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in train_dist_dataset:\n",
    "      total_loss += distributed_train_step(x)\n",
    "      num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # 테스트 루프\n",
    "    for x in test_dist_dataset:\n",
    "      distributed_test_step(x)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "      checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "    template = (\"에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, \"\n",
    "                \"테스트 정확도: {}\")\n",
    "    print (template.format(epoch+1, train_loss,\n",
    "                           train_accuracy.result()*100, test_loss.result(),\n",
    "                           test_accuracy.result()*100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='eval_accuracy')\n",
    "\n",
    "new_model = create_model()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(images, labels):\n",
    "  predictions = new_model(images, training=False)\n",
    "  eval_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: 90.8699951171875\n"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "  eval_step(images, labels)\n",
    "\n",
    "print ('전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: {}'.format(\n",
    "    eval_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}